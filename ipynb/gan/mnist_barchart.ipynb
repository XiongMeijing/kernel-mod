{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "#%config InlineBackend.figure_format = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kmod\n",
    "import kmod.glo as glo\n",
    "import kmod.plot as plot\n",
    "import kmod.util as util\n",
    "import kmod.kernel as kernel\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "import torch.autograd\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from kmod.gan_ume_opt import ume_power_criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# font options\n",
    "font = {\n",
    "    #'family' : 'normal',\n",
    "    #'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('lines', linewidth=2)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this to False to avoid using a GPU\n",
    "use_cuda = False and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "default_type = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "torch.set_default_tensor_type(default_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a model from the shared folder\n",
    "shared_resource_path = glo.shared_resource_folder()\n",
    "model_folder = glo.shared_resource_folder('prob_models', 'mnist_cnn')\n",
    "epochs = 20\n",
    "seed = 1\n",
    "model_fname = 'mnist_cnn_ep{}_s{}.pt'.format(epochs, seed)\n",
    "model_fpath = os.path.join(model_folder, model_fname)\n",
    "\n",
    "print('Shared resource path at: {}'.format(shared_resource_path))\n",
    "print('Model folder: {}'.format(model_folder))\n",
    "print('Model file: ', model_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from kmod.mnist.classify import MnistClassifier\n",
    "# load option depends on whether GPU is used\n",
    "load_options = {} if use_cuda else {'map_location': lambda storage, loc: storage} \n",
    "classifier = MnistClassifier.load(model_fpath, **load_options)\n",
    "# evaluation mode\n",
    "classifier = classifier.eval().to(device)\n",
    "# classifier is a torch.nn.Module\n",
    "display(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x, loc, scale):\n",
    "    return (x - loc) / scale\n",
    "\n",
    "\n",
    "def mnist_norm(x):\n",
    "    return norm(x, 0.1307, 0.3081)\n",
    "\n",
    "\n",
    "def trans_gan(x):\n",
    "    y = norm(x, -1.0, 2.0)\n",
    "    return mnist_norm(y)\n",
    "\n",
    "def trans_vae(x):\n",
    "    return mnist_norm(x).view(-1, 1, 28, 28)\n",
    "\n",
    "def get_trans(model_type):\n",
    "    name = model_type.lower()\n",
    "    key_list = ['dcgan', 'began']\n",
    "    if name not in key_list:\n",
    "        raise ValueError('Model name has be one of '\n",
    "                          '{} and was'.format(key_list, name))\n",
    "        \n",
    "    if name == 'began':\n",
    "        return trans_gan\n",
    "    elif name == 'dcgan':\n",
    "        return trans_gan\n",
    "    elif name == 'vae':\n",
    "        return mnist_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmod.mnist.dcgan import Generator\n",
    "from kmod.mnist.dcgan import DCGAN\n",
    "import kmod.mnist.dcgan as mnist_dcgan\n",
    "import kmod.net as net\n",
    "import kmod.gen as gen\n",
    "\n",
    "def vae_sample(vae, n):\n",
    "    sample = torch.randn(n, 20).to(device)\n",
    "    gen_imgs = vae.decode(sample)\n",
    "    #bern = torch.distributions.Bernoulli(probs=gen_imgs)\n",
    "    #return bern.sample().view(n, -1, 28, 28)\n",
    "    return gen_imgs.detach().view(n, -1, 28, 28)\n",
    "\n",
    "def load_model(model_name, epoch, batch_size=64):\n",
    "    name = model_name.lower()\n",
    "    key_list = ['dcgan', 'began']\n",
    "    if name not in key_list:\n",
    "        raise ValueError('Model name has be one of '\n",
    "                          '{} and was'.format(key_list, name))\n",
    "    print('Loading ', name)\n",
    "    if name == 'dcgan':\n",
    "        # load a model from the shared folder\n",
    "        model_folder = glo.shared_resource_folder('prob_models', 'mnist_dcgan')\n",
    "        model_fname = 'mnist_dcgan_ep{}_bs{}.pt'.format(epoch, batch_size)\n",
    "        model_fpath = os.path.join(model_folder, model_fname)\n",
    "        print('Shared resource path at: {}'.format(shared_resource_path))\n",
    "        print('Model folder: {}'.format(model_folder))\n",
    "        print('Model file: ', model_fname)\n",
    "        # load the generator of type kmod.gen.PTNoiseTransformer\n",
    "        dcgan = net.SerializableModule.load(model_fpath, **load_options)\n",
    "        return dcgan\n",
    "    \n",
    "    if name == 'began':\n",
    "        # load a model from the shared folder\n",
    "        model_folder = glo.shared_resource_folder('prob_models', 'mnist_began', str(epoch))\n",
    "        model_fname = 'BEGAN_G.pkl'\n",
    "        model_fpath = os.path.join(model_folder, model_fname)\n",
    "        print('Shared resource path at: {}'.format(shared_resource_path))\n",
    "        print('Model folder: {}'.format(model_folder))\n",
    "        print('Model file: ', model_fname)\n",
    "        \n",
    "        from kmod.mnist.began import Generator as BeganGenerator\n",
    "        # load the generator of type kmod.gen.PTNoiseTransformer\n",
    "        image_size = 28\n",
    "        z_dim = 62 #dimention of noise, this is fixed. so don't change\n",
    "        g = BeganGenerator(input_dim=z_dim,input_size=image_size)\n",
    "        in_out_shapes = (z_dim, image_size)\n",
    "        def f_sample_noise(n):\n",
    "            return torch.rand((n, z_dim))\n",
    "        g.load(model_fpath, **load_options)\n",
    "        #print(g.fc[0].weight.is_cuda)\n",
    "        began = gen.PTNoiseTransformerAdapter(module=g, f_sample_noise=f_sample_noise, \n",
    "                                          in_out_shapes=in_out_shapes, tensor_type=default_type)\n",
    "        return began"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models and generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type_p = 'began'\n",
    "gen_p = load_model(model_type_p, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_type_q = 'began'\n",
    "gen_q = load_model(model_type_q, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gen = 10000\n",
    "gen_imgs_p = gen_p.sample(n_gen)\n",
    "\n",
    "n_show = 20*5\n",
    "plt.figure(figsize=(8, 5))\n",
    "plot.show_torch_imgs(gen_imgs_p[:n_show], nrow=20, figsize=(8, 5), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gen = 10000\n",
    "gen_imgs_q = gen_q.sample(n_gen)\n",
    "\n",
    "n_show = 20*5\n",
    "plt.figure(figsize=(8, 5))\n",
    "plot.show_torch_imgs(gen_imgs_q[:n_show], nrow=20, figsize=(8, 5), normalize=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Load VAE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from kmod.mnist.vae import VAE\n",
    "epochs = 20\n",
    "model_folder = glo.shared_resource_folder('prob_models', 'mnist_vae', str(epochs))\n",
    "model_fname = 'VAE.pkl'.format(epochs, batch_size)\n",
    "model_fpath = os.path.join(model_folder, model_fname)\n",
    "vae = VAE()\n",
    "vae.load_state_dict(torch.load(model_fpath))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gen_imgs_q = torch.tensor(vae_sample(vae, n_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_p = get_trans(model_type_p)\n",
    "trans_q = get_trans(model_type_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = []\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "for i in range(0, n_gen, batch_size):\n",
    "    x = gen_imgs_p[i:i+batch_size]\n",
    "    x = trans_dcgan(x)\n",
    "    pred = torch.argmax(classifier(x), dim=1)\n",
    "    pred_results.append(pred)\n",
    "pred_results_p = torch.cat(pred_results)\n",
    "pred_num_p = []\n",
    "for i in range(10):\n",
    "    pred_num_p.append(torch.sum(pred_results_p==i).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = []\n",
    "batch_size = 100\n",
    "for i in range(0, n_gen, batch_size):\n",
    "    x = gen_imgs_q[i:i+batch_size]\n",
    "    x = mnist_norm(x)\n",
    "    pred = torch.argmax(classifier(x), dim=1)\n",
    "    pred_results.append(pred)\n",
    "pred_results_q = torch.cat(pred_results)\n",
    "pred_num_q = []\n",
    "for i in range(10):\n",
    "    pred_num_q.append(torch.sum(pred_results_q==i).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('class')\n",
    "plt.ylabel('pred[%]')\n",
    "plt.bar(np.arange(10), pred_num_p/np.sum(pred_num_p)*100, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('class')\n",
    "plt.ylabel('pred[%]')\n",
    "plt.bar(np.arange(10), pred_num_q/np.sum(pred_num_q)*100, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "index = np.arange(10)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "pred_per_p = pred_num_p / np.sum(pred_num_p) * 100\n",
    "pred_per_q = pred_num_q / np.sum(pred_num_q) * 100\n",
    "\n",
    "rects1 = plt.bar(index, pred_per_p, bar_width, alpha=opacity,\n",
    "                color='g', label='began e=40')\n",
    "rects2 = plt.bar(index+bar_width, pred_per_q, bar_width, alpha=opacity,\n",
    "                color='b', label='began e=3')\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('pred[%]')\n",
    "ax.legend(loc='right', bbox_to_anchor=(1.75, 0.25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power criterion bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(imgs):\n",
    "    \"\"\"\n",
    "    Feature extractor\n",
    "    \"\"\"\n",
    "    self = classifier\n",
    "    x = imgs\n",
    "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "    x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "    x = x.view(-1, 320)\n",
    "    return x\n",
    "\n",
    "def extractor_cls(imgs):\n",
    "    self = classifier\n",
    "    x = imgs\n",
    "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "    x = x.view(-1, 320)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = extractor_cls\n",
    "# load MNIST data\n",
    "mnist_folder = glo.data_file('mnist')\n",
    "mnist_dataset = torchvision.datasets.MNIST(mnist_folder, train=False, \n",
    "                        transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = 2000\n",
    "num_classes = 10\n",
    "J = 30\n",
    "reg = 1e-4\n",
    "n_sample_per_class = num_sample // num_classes\n",
    "len_data = len(mnist_dataset)\n",
    "input_Z = []\n",
    "mnist_Y = torch.stack([mnist_dataset[i][1] for i in range(len_data)])\n",
    "mnist_X = torch.stack([mnist_dataset[i][0] for i in range(len_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_array(arr, sizes):\n",
    "    if not sizes or sum(sizes) == 0 or len(sizes) == 0:\n",
    "        raise ValueError('sizes cannot be empty. Was {}'.format(sizes))\n",
    "    sub_arrs = []\n",
    "    idx = 0\n",
    "    for i in range(0, len(sizes)):\n",
    "        sub_arrs.append(arr[idx: idx+sizes[i]])\n",
    "        idx += sizes[i]\n",
    "    return sub_arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 100\n",
    "results = np.empty([num_trials, num_classes])\n",
    "\n",
    "for i in range(num_trials):\n",
    "    seed = i\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    #X = featurizer(trans_dcgan(dcgan.sample(num_sample)))\n",
    "    X = featurizer(trans_p(gen_p.sample(num_sample)))\n",
    "    #Y = featurizer(mnist_norm(vae_sample(vae, num_sample)))\n",
    "    Y = featurizer(trans_q(gen_q.sample(num_sample)))\n",
    "    V_list = []\n",
    "    Z_list = []\n",
    "    for j in range(num_classes):\n",
    "        idx = (mnist_Y == j)\n",
    "        rand_idx = util.subsample_ind(len(mnist_Y[idx]), len(mnist_Y[idx]), seed=seed)\n",
    "        Z, V = slice_array(mnist_X[idx][rand_idx], [n_sample_per_class, J]) \n",
    "        Z_list.append(Z)\n",
    "        V_list.append(V)\n",
    "    Z = torch.cat(Z_list).to(device)\n",
    "    Z = featurizer(Z)\n",
    "    \n",
    "    XYZ = np.vstack((X.cpu().data.numpy(), Y.cpu().data.numpy(), Z.cpu().data.numpy()))\n",
    "    med = util.meddistance(XYZ, subsample=1000)\n",
    "    gwidth2 = torch.tensor(med**2, requires_grad=True, device=device)\n",
    "    k = kernel.PTKGauss(gwidth2)\n",
    "    for j in range(num_classes):\n",
    "        V = V_list[j]\n",
    "        V = featurizer(V.to(device))\n",
    "        results[i, j] = ume_power_criterion(X, Y, Z, V, V, k, reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('class')\n",
    "plt.ylabel('power criterion')\n",
    "plt.bar(np.arange(10), np.mean(results, 0), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.std(results, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
